{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c12575",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "\n",
    "# For example, here are several helpful packages to load in\n",
    "\n",
    "import os\n",
    "import string\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from funcsigs import signature\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    multilabel_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data dir\n",
    "data_dir = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a470f",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{data_dir}/train.csv\")  # limiting the rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(f\"{data_dir}/valid.csv\")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235901ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{data_dir}/valid.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331330f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset splits for training etc\n",
    "\n",
    "X_train = train_df[\"text\"]\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "X_val = val_df[\"text\"]\n",
    "y_val = val_df[\"label\"]\n",
    "\n",
    "X_test = test_df[\"text\"]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44f2df61",
   "metadata": {},
   "source": [
    "# Train, etc. using `sklearn` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first come cleaning and preprocessing functions\n",
    "\n",
    "# create list of punctuations\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# create list of stop words\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349efd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacy English parser with tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f080b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spacy tokenizer function\n",
    "\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    # create a spacy token object\n",
    "    # print(f\"Raw sentence was: {sentence}\")\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    mytokens = [word.lower_ for word in mytokens]\n",
    "\n",
    "    # remove STOP WORDS\n",
    "    mytokens = [\n",
    "        word for word in mytokens if word not in stop_words and word not in punctuations\n",
    "    ]\n",
    "    # print(f\"my tokens after removal of stop: {mytokens}\")\n",
    "\n",
    "    # return processed tokens\n",
    "\n",
    "    return mytokens\n",
    "\n",
    "\n",
    "def spacy_tokenizer_lemmatize(sentence):\n",
    "    # create a spacy token object\n",
    "    # print(f\"Raw sentence was: {sentence}\")\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # lemmatize each token and convert to lowercase\n",
    "    mytokens = [\n",
    "        word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_\n",
    "        for word in mytokens\n",
    "    ]\n",
    "    mytokens = [word.lower_ for word in mytokens]\n",
    "\n",
    "    # remove STOP WORDS\n",
    "    mytokens = [\n",
    "        word for word in mytokens if word not in stop_words and word not in punctuations\n",
    "    ]\n",
    "    # print(f\"my tokens after removal of stop: {mytokens}\")\n",
    "\n",
    "    # return processed tokens\n",
    "\n",
    "    return mytokens\n",
    "\n",
    "\n",
    "# custom transformer class using spaCy\n",
    "\n",
    "\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # clean text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, x, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ea670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b3b9e",
   "metadata": {},
   "source": [
    "Wrap preprocessing and training etc into a few functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462206b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(clf, clf_name_str, save_dir):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    print(f\"Saving trained model at: {save_dir}/{clf_name_str}.joblib\")\n",
    "\n",
    "\n",
    "def setup_vectorised_data(\n",
    "    path_to_data,\n",
    "    text_col=\"text\",\n",
    "    label_col=\"label\",\n",
    "    max_features=50000,\n",
    "    vectorizer=\"tfidf\",\n",
    "    pretrained_vect_dir=None,\n",
    "    save_vectorizer=True,\n",
    "    save_dir=None,\n",
    "    ngram_range=(1, 2),\n",
    "    lemmatize=False,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Function: Given a dataset with text and labels - vectorise using scikit-learn\n",
    "    methods and return feature vectors for downstream training and/or testing\n",
    "\n",
    "    args:\n",
    "\n",
    "        path_to_data: String -> the directory containing the raw dataset\n",
    "        text_col:  String -> the column of dataframe containing the raw text\n",
    "        label_col: String -> the column of the dataframe containing the target/class\n",
    "        label\n",
    "        max_features: Int -> maximum number of features i.e. vocab size for the\n",
    "        vectorizer\n",
    "        vectorizer: String -> the string identifier for the scikit learn vectorization\n",
    "        method to use - options are tfidf or bow\n",
    "        pretrained_vect_dir: String -> if a vectorizer has already been fitted to\n",
    "        training data and is to be loaded in rather than fitting a new one,\n",
    "        provide path to saved vectorizer\n",
    "        save_vectorizer: Boolean -> whether or not to save the fitted vectorizer\n",
    "        save_dir: String -> path to save the fitted vectorizer\n",
    "        ngram_range: Tuple -> (low,max) range for the ngrams to be used when\n",
    "        creating vectors\n",
    "        lemmatize: Boolean -> whether or not to apply lemmatization when using\n",
    "        spacy tokenizer\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    train_data = pd.read_csv(f\"{path_to_data}/train.csv\", index_col=None)\n",
    "    # lets shuffle the data\n",
    "    train_data = shuffle(train_data, random_state=42)\n",
    "    valid_data = pd.read_csv(f\"{path_to_data}/valid.csv\", index_col=None)\n",
    "    test_data = pd.read_csv(f\"{path_to_data}/test.csv\", index_col=None)\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            f\"Train data shape: {train_data.shape} with label counts: \"\n",
    "            f\"{train_data.label.value_counts()}\\n\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        (\n",
    "            f\"Validation data shape: {valid_data.shape} with label counts: \"\n",
    "            f\"{valid_data.label.value_counts()}\\n\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        (\n",
    "            f\"Test data shape: {test_data.shape} with label counts: \"\n",
    "            f\"{test_data.label.value_counts()}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # extract the text and label data\n",
    "    X_train = train_data[text_col]\n",
    "    y_train = train_data[label_col].astype(\"int64\")\n",
    "    X_valid = valid_data[text_col]\n",
    "    y_valid = valid_data[label_col].astype(\"int64\")\n",
    "    X_test = test_data[text_col]\n",
    "    y_test = test_data[label_col].astype(\"int64\")\n",
    "\n",
    "    # are we lemmatizing?\n",
    "    if lemmatize:\n",
    "        print(\"Will be lemmatizing - be warned this can remove a lot of data\")\n",
    "        tokenizer = spacy_tokenizer_lemmatize\n",
    "    else:\n",
    "        tokenizer = spacy_tokenizer\n",
    "\n",
    "    # use pretrained vectorizer?\n",
    "    if vectorizer == \"pretrained\":\n",
    "        print(f\"Loading pretrained vectorizer from: {pretrained_vect_dir}\")\n",
    "        vect = joblib.load(pretrained_vect_dir)\n",
    "\n",
    "    elif vectorizer == \"count\":\n",
    "        print(f\"Using count vectorizer with {max_features} max features\")\n",
    "        vect = CountVectorizer(\n",
    "            max_features=max_features, tokenizer=tokenizer, ngram_range=ngram_range\n",
    "        )\n",
    "        # fit to train data\n",
    "        vect.fit(X_train.values)\n",
    "\n",
    "    elif vectorizer == \"tfidf\":\n",
    "        print(f\"Using tfidf vectorizer\")\n",
    "        vect = TfidfVectorizer(\n",
    "            max_features=max_features, tokenizer=tokenizer, ngram_range=ngram_range\n",
    "        )\n",
    "        # fit to train data\n",
    "        vect.fit(X_train.values)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # now transform the data\n",
    "    print(f\"Transforming training data!\")\n",
    "    X_train_tf = vect.transform(X_train.values)\n",
    "    print(f\"Transforming validation data!\")\n",
    "    X_valid_tf = vect.transform(X_valid.values)\n",
    "    print(f\"Transforming test data!\")\n",
    "    X_test_tf = vect.transform(X_test.values)\n",
    "\n",
    "    # save vectorizer if desired\n",
    "    if save_vectorizer:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        print(f\"Saving vectorizer at: {save_dir}\")\n",
    "        joblib.dump(vect, f\"{save_dir}/{vectorizer}.joblib\")\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            f\"Shape of vectorized data:\\n\\n Train:{X_train_tf.shape}\\n\"\n",
    "            f\"Valid:{X_valid_tf.shape}\\nTest:{X_test_tf.shape}\"\n",
    "        )\n",
    "    )\n",
    "    return X_train_tf, y_train, X_valid_tf, y_valid, X_test_tf, y_test\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    X_train_tf,\n",
    "    y_train,\n",
    "    X_valid_tf,\n",
    "    y_valid,\n",
    "    X_test_tf,\n",
    "    y_test,\n",
    "    save_dir,\n",
    "    clf_name=None,\n",
    "    save_model=True,\n",
    "    run_grid=False,\n",
    "):\n",
    "\n",
    "    print(f\"Running training!\")\n",
    "\n",
    "    # set up clf and fit/train\n",
    "    model = clf_name\n",
    "    clf_name_str = str(clf_name).split(\"(\")[0]\n",
    "    # do CV for RF\n",
    "    if clf_name_str == \"RandomForestClassifier\" and run_grid:\n",
    "        print(f\"Running grid search to find optimal hyperparams for random forest\")\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [50, 200, 500],\n",
    "            \"max_features\": [\"sqrt\", \"log2\"],\n",
    "            \"max_depth\": [4, 6, 8, 10, 15, 20],\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "        }\n",
    "\n",
    "        CV_rfc = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "        CV_rfc.fit(X_train_tf, y_train)\n",
    "        best_params = CV_rfc.best_params_\n",
    "        print(f\"Best params for RF were: {best_params}\")\n",
    "        model = RandomForestClassifier(**best_params)\n",
    "\n",
    "    # now fit to training data\n",
    "    model.fit(X_train_tf, y_train)\n",
    "\n",
    "    # if save model\n",
    "    if save_model:\n",
    "        save_trained_model(model, clf_name_str=clf_name_str, save_dir=save_dir)\n",
    "\n",
    "    return model, clf_name_str\n",
    "\n",
    "\n",
    "def run_evaluation(\n",
    "    model,\n",
    "    X_train_tf,\n",
    "    y_train,\n",
    "    X_valid_tf,\n",
    "    y_valid,\n",
    "    X_test_tf,\n",
    "    y_test,\n",
    "    save_dir,\n",
    "    threshold=0.5,\n",
    "):\n",
    "\n",
    "    print(\"Running evaluation!\")\n",
    "\n",
    "    # get model predicts and probabilities\n",
    "    y_train_preds = model.predict(X_train_tf)\n",
    "    y_train_pred_probs = model.predict_proba(X_train_tf)[:, 1]\n",
    "    y_valid_preds = model.predict(X_valid_tf)\n",
    "    y_valid_pred_probs = model.predict_proba(X_valid_tf)[:, 1]\n",
    "    y_test_preds = model.predict(X_test_tf)\n",
    "    y_test_pred_probs = model.predict_proba(X_test_tf)[:, 1]\n",
    "\n",
    "    # set up save dir\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    target_names = [\"low-severity\", \"high-severity\"]\n",
    "\n",
    "    def calc_accuracy(y_actual, y_pred, thresh):\n",
    "        return (\n",
    "            sum((y_pred > thresh) & (y_actual == 1))\n",
    "            + sum((y_pred < thresh) & (y_actual == 0))\n",
    "        ) / len(y_actual)\n",
    "\n",
    "    def calc_recall(y_actual, y_pred, thresh):\n",
    "        return sum((y_pred > thresh) & (y_actual == 1)) / sum(y_actual)\n",
    "\n",
    "    def calc_precision(y_actual, y_pred, thresh):\n",
    "        return sum((y_pred > thresh) & (y_actual == 1)) / sum(y_pred > thresh)\n",
    "\n",
    "    def calc_specificity(y_actual, y_pred, thresh):\n",
    "        return sum((y_pred < thresh) & (y_actual == 0)) / sum(y_actual == 0)\n",
    "\n",
    "    def calc_prevelance(y_actual, y_pred, thresh):\n",
    "        return sum((y_actual == 1)) / len(y_actual)\n",
    "\n",
    "    fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_pred_probs)\n",
    "    fpr_valid, tpr_valid, thresholds_valid = roc_curve(y_valid, y_valid_pred_probs)\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_pred_probs)\n",
    "\n",
    "    thresh = threshold\n",
    "\n",
    "    auc_train = roc_auc_score(y_train, y_train_pred_probs)\n",
    "    auc_valid = roc_auc_score(y_valid, y_valid_pred_probs)\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred_probs)\n",
    "\n",
    "    print(f\"Train AUC: {auc_train}\")\n",
    "    print(f\"Valid AUC: {auc_valid}\")\n",
    "    print(f\"Test AUC: {auc_test}\")\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            \"Train accuracy: \"\n",
    "            f\"{calc_accuracy(y_train, y_train_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        (\n",
    "            \"Valid accuracy: \"\n",
    "            f\"{calc_accuracy(y_valid, y_valid_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Test accuracy: {calc_accuracy(y_test, y_test_pred_probs, thresh = thresh)}\")\n",
    "\n",
    "    print(f\"Train recall: {calc_recall(y_train, y_train_pred_probs, thresh = thresh)}\")\n",
    "    print(f\"Valid recall: {calc_recall(y_valid, y_valid_pred_probs, thresh = thresh)}\")\n",
    "    print(f\"Test recall: {calc_recall(y_test, y_test_pred_probs, thresh = thresh)}\")\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            \"Train precision: \"\n",
    "            f\"{calc_precision(y_train, y_train_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        (\n",
    "            \"Valid precision: \"\n",
    "            f\"{calc_precision(y_valid, y_valid_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        f\"Test precision: {calc_precision(y_test, y_test_pred_probs, thresh = thresh)}\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            \"Train specificity: \"\n",
    "            f\"{calc_specificity(y_train, y_train_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            \"Valid specificity: \"\n",
    "            f\"{calc_specificity(y_valid, y_valid_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        (\n",
    "            \"Test specificity: \"\n",
    "            f\"{calc_specificity(y_test, y_test_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            \"Train class prevelance: \"\n",
    "            f\"{calc_prevelance(y_train, y_train_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        (\n",
    "            \"Valid class prevelance: \"\n",
    "            f\"{calc_prevelance(y_valid, y_valid_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        (\n",
    "            \"Test class prevelance: \"\n",
    "            f\"{calc_prevelance(y_test, y_test_pred_probs, thresh = thresh)}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # make plots\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(fpr_train, tpr_train, \"r-\", label=f\"Train AUC: {auc_train:.2f}\")\n",
    "    plt.plot(fpr_valid, tpr_valid, \"b-\", label=f\"Train AUC: {auc_valid:.2f}\")\n",
    "    plt.plot(fpr_test, tpr_test, \"g-\", label=f\"Train AUC: {auc_test:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"-k\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.suptitle(\"Evaluation - AUC ROC\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{save_dir}/eval_auc_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # now for precision-recall curve for test data\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_test_pred_probs)\n",
    "    area = auc(recall, precision)\n",
    "\n",
    "    step_kwargs = (\n",
    "        {\"step\": \"post\"} if \"step\" in signature(plt.fill_between).parameters else {}\n",
    "    )\n",
    "    plt.figure(2)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color=\"b\", **step_kwargs)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(f\"Precision-recall curve: AUC = {area}\")\n",
    "    plt.savefig(f\"{save_dir}/eval_auprc_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Test classification report\\n\")\n",
    "    print(classification_report(y_test, y_test_preds, target_names=target_names))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_test_preds, normalize=\"true\")\n",
    "    df_cm = pd.DataFrame(cm, target_names, target_names)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.suptitle(\"Low severity vs high severity reports\")\n",
    "    sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "    plt.savefig(f\"{save_dir}/test_confusion_matrix.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data dir and save dirs\n",
    "data_dir = \"<INSERT DATA DIRECTORY>\"\n",
    "save_dir = \"<INSERT SAVE DIRECTORY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49afaa",
   "metadata": {},
   "source": [
    "## Experiment 1 - Random Forest - default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb308352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up arguments\n",
    "\n",
    "do_training = True\n",
    "do_evaluation = True\n",
    "load_model = False\n",
    "run_grid = False\n",
    "load_vect = False\n",
    "save_vect = True\n",
    "save_model = True\n",
    "lemmatize = False\n",
    "max_features = 50000\n",
    "ngram_range = (1, 2)\n",
    "vectorizer = \"tfidf\"\n",
    "vectorizer_to_load = None\n",
    "# assert vectorizer is not both loaded and saved\n",
    "assert (\n",
    "    load_vect != save_vect\n",
    "), \"if a vecotrizer is being loaded - do not want to save it again\"\n",
    "# assert load model is not true when train is also true\n",
    "assert (\n",
    "    load_model != do_training\n",
    "), \"if loading a clf model - do not want to train it again?\"\n",
    "\n",
    "if load_vect:\n",
    "    vectorizer = \"pretrained\"\n",
    "    vectorizer_to_load = None  # put path to saved vectorizer\n",
    "\n",
    "# set up save directories\n",
    "if lemmatize:\n",
    "    model_dir = f\"{save_dir}/models/{vectorizer}_features_{max_features}_lemmatized/\"\n",
    "\n",
    "else:\n",
    "    model_dir = f\"{save_dir}/models/{vectorizer}_features_{max_features}/\"\n",
    "\n",
    "# set up vectorized data\n",
    "X_train_tf, y_train, X_valid_tf, y_valid, X_test_tf, y_test = setup_vectorised_data(\n",
    "    path_to_data=data_dir,\n",
    "    text_col=\"text\",\n",
    "    label_col=\"label\",\n",
    "    max_features=max_features,\n",
    "    vectorizer=vectorizer,\n",
    "    save_dir=model_dir,\n",
    "    pretrained_vect_dir=vectorizer_to_load,\n",
    "    save_vectorizer=save_vect,\n",
    "    ngram_range=ngram_range,\n",
    "    lemmatize=lemmatize,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ec2df",
   "metadata": {},
   "source": [
    "### ***IMPORTANT***- if you have already created the train/valid/test vectors - then just rename the model and run below to get new train/test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)\n",
    "\n",
    "# if we are doing training\n",
    "if do_training:\n",
    "    model, clf_name_str = run_training(\n",
    "        X_train_tf,\n",
    "        y_train,\n",
    "        X_valid_tf,\n",
    "        y_valid,\n",
    "        X_test_tf,\n",
    "        y_test,\n",
    "        save_dir=model_dir,\n",
    "        clf_name=clf_name,\n",
    "        save_model=True,\n",
    "        run_grid=run_grid,\n",
    "    )\n",
    "\n",
    "# set up save directories\n",
    "if lemmatize:\n",
    "    results_dir = (\n",
    "        f\"{save_dir}/results/{vectorizer}_features_{max_features}\"\n",
    "        \"_lemmatized/clf_name_str/\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    results_dir = (\n",
    "        f\"{save_dir}/results/{vectorizer}_features_{max_features}/clf_name_str/\"\n",
    "    )\n",
    "\n",
    "if load_model:\n",
    "    print(f\"Loading model from:...\")\n",
    "\n",
    "if do_evaluation:\n",
    "    run_evaluation(\n",
    "        model,\n",
    "        X_train_tf,\n",
    "        y_train,\n",
    "        X_valid_tf,\n",
    "        y_valid,\n",
    "        X_test_tf,\n",
    "        y_test,\n",
    "        save_dir=results_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment 2 - Random forest with grid search\n",
    "# set up arguments\n",
    "\n",
    "# do_training = True\n",
    "# do_evaluation = True\n",
    "# load_model = False\n",
    "# run_grid = True\n",
    "# load_vect = False\n",
    "# save_vect = True\n",
    "# save_model = True\n",
    "# lemmatize = False\n",
    "# max_features = 50000\n",
    "# ngram_range = (1,2)\n",
    "# vectorizer = \"tfidf\"\n",
    "# vectorizer_to_load = None\n",
    "# # assert vectorizer is not both loaded and saved\n",
    "# assert load_vect != save_vect,\n",
    "# # \"if a vectorizer is being loaded - do not want to save it again\"\n",
    "# # assert load model is not true when train is also true\n",
    "# assert load_model != do_training, \"if loading a clf model - do not want to train it again?\"\n",
    "\n",
    "# if load_vect:\n",
    "#     vectorizer = \"pretrained\"\n",
    "#     vectorizer_to_load = None # put path to saved vectorizer\n",
    "\n",
    "# # set up save directories\n",
    "# if lemmatize:\n",
    "#     model_dir = f\"{save_dir}/models/{vectorizer}_features_{max_features}_lemmatized/\"\n",
    "\n",
    "# else:\n",
    "#     model_dir = f\"{save_dir}/models/{vectorizer}_features_{max_features}/\"\n",
    "\n",
    "# # set up vectorized data\n",
    "# (\n",
    "#   X_train_tf,\n",
    "#   y_train,\n",
    "#   X_valid_tf,\n",
    "#   y_valid,\n",
    "#   X_test_tf,\n",
    "#   y_test\n",
    "# ) = setup_vectorised_data(\n",
    "#       path_to_data=data_dir,\n",
    "#       text_col= 'text',\n",
    "#       label_col='label',\n",
    "#       max_features=max_features,\n",
    "#       vectorizer=vectorizer,\n",
    "#       save_dir= model_dir,\n",
    "#       pretrained_vect_dir=vectorizer_to_load,\n",
    "#       save_vectorizer=save_vect,\n",
    "#       ngram_range=ngram_range,\n",
    "#       lemmatize=lemmatize\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_grid = True\n",
    "clf_name = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)\n",
    "\n",
    "# if we are doing training\n",
    "if do_training:\n",
    "    model, clf_name_str = run_training(\n",
    "        X_train_tf,\n",
    "        y_train,\n",
    "        X_valid_tf,\n",
    "        y_valid,\n",
    "        X_test_tf,\n",
    "        y_test,\n",
    "        save_dir=model_dir,\n",
    "        clf_name=clf_name,\n",
    "        save_model=True,\n",
    "        run_grid=run_grid,\n",
    "    )\n",
    "\n",
    "# set up save directories\n",
    "if lemmatize:\n",
    "    results_dir = (\n",
    "        f\"{save_dir}/results/{vectorizer}_features_{max_features}\"\n",
    "        \"_lemmatized/clf_name_str/\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    results_dir = (\n",
    "        f\"{save_dir}/results/{vectorizer}_features_{max_features}/clf_name_str/\"\n",
    "    )\n",
    "\n",
    "if load_model:\n",
    "    print(f\"Loading model from:...\")\n",
    "\n",
    "if do_evaluation:\n",
    "    run_evaluation(\n",
    "        model,\n",
    "        X_train_tf,\n",
    "        y_train,\n",
    "        X_valid_tf,\n",
    "        y_valid,\n",
    "        X_test_tf,\n",
    "        y_test,\n",
    "        save_dir=results_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b265873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "elm4psir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:53:40) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "036f9b356400688fa32ab139d64151f7af42c87240ca002d464048bf8c685a85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
